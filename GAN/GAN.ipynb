{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xnQ1kK61Frqu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pandas as pd\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hd5_mbySF2W6",
        "outputId": "eaa0a336-84de-4c25-a23e-bccef924a785"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "r4Rm0RQmFrq4"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/archive/creditcard.csv')\n",
        "\n",
        "# Select features (excluding label 'Fraud')\n",
        "df = df[df['Class'] == 1]\n",
        "features = df.drop(columns=['Class']).values\n",
        "labels = df['Class'].values  # Use labels for evaluation, not for GAN training\n",
        "\n",
        "# Normalize the data for better GAN performance\n",
        "scaler = MinMaxScaler()\n",
        "features_scaled = scaler.fit_transform(features)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "real_data = torch.tensor(features_scaled, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "a2IjWjcyFrq7"
      },
      "outputs": [],
      "source": [
        "# Generator Model\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, output_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Discriminator Model\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oyt0H0XZFrq-"
      },
      "outputs": [],
      "source": [
        "input_dim = real_data.shape[1]  # Number of features in the dataset\n",
        "z_dim = 20  # Latent space size for generator\n",
        "\n",
        "generator = Generator(z_dim, input_dim)\n",
        "discriminator = Discriminator(input_dim)\n",
        "\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "lr = 0.0002\n",
        "\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002)\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0001)  # Slower learning for D\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUXtdkJSFrrB",
        "outputId": "024c987c-fd94-4736-fdfa-39b724cb3e9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/11000, D Loss: 1.3497087955474854, G Loss: 0.7522888779640198\n",
            "Epoch 1000/11000, D Loss: 1.402297019958496, G Loss: 0.7600400447845459\n",
            "Epoch 2000/11000, D Loss: 1.2091701030731201, G Loss: 0.8461102247238159\n",
            "Epoch 3000/11000, D Loss: 1.3039371967315674, G Loss: 0.7668817043304443\n",
            "Epoch 4000/11000, D Loss: 1.3870747089385986, G Loss: 0.7200126647949219\n",
            "Epoch 5000/11000, D Loss: 1.3854877948760986, G Loss: 0.7147045731544495\n",
            "Epoch 6000/11000, D Loss: 1.4612627029418945, G Loss: 0.6949764490127563\n",
            "Epoch 7000/11000, D Loss: 1.3997976779937744, G Loss: 0.7400786876678467\n",
            "Epoch 8000/11000, D Loss: 1.3237571716308594, G Loss: 0.7427411079406738\n",
            "Epoch 9000/11000, D Loss: 1.2130829095840454, G Loss: 0.8037952184677124\n",
            "Epoch 10000/11000, D Loss: 1.3109478950500488, G Loss: 0.7682338953018188\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "num_epochs = 11000\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # Select a random batch from real data\n",
        "    idx = torch.randint(0, real_data.size(0), (batch_size,))\n",
        "    real_batch = real_data[idx]\n",
        "\n",
        "    noise = torch.randn_like(real_batch) * 0.05\n",
        "    real_batch_noisy = real_batch + noise\n",
        "\n",
        "\n",
        "    # Generate fake data\n",
        "    z = torch.randn(batch_size, z_dim)\n",
        "    fake_data = generator(z)\n",
        "\n",
        "    # Labels for real (1) and fake (0)\n",
        "    real_labels = torch.full((batch_size, 1), 0.9)  # Instead of 1\n",
        "    fake_labels = torch.full((batch_size, 1), 0.1)  # Instead of 0\n",
        "\n",
        "\n",
        "    # Train Discriminator\n",
        "    real_loss = criterion(discriminator(real_batch_noisy), real_labels)\n",
        "    fake_loss = criterion(discriminator(fake_data.detach()), fake_labels)\n",
        "    d_loss = real_loss + fake_loss\n",
        "\n",
        "    optimizer_D.zero_grad()\n",
        "    d_loss.backward()\n",
        "    optimizer_D.step()\n",
        "\n",
        "    # Train Generator\n",
        "    g_loss = criterion(discriminator(fake_data), real_labels)\n",
        "\n",
        "    optimizer_G.zero_grad()\n",
        "    g_loss.backward()\n",
        "    optimizer_G.step()\n",
        "\n",
        "    if epoch % 1000 == 0:\n",
        "        print(f\"Epoch {epoch}/{num_epochs}, D Loss: {d_loss.item()}, G Loss: {g_loss.item()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/archive/creditcard.csv')\n",
        "\n",
        "fraud = df[df['Class'] == 1]\n",
        "legit = df[df['Class'] == 0]\n",
        "\n",
        "fraud_train, fraud_test = train_test_split(fraud, test_size=0.3, random_state=42)\n",
        "legit_train, legit_test = train_test_split(legit, test_size=0.3, random_state=42)\n",
        "\n",
        "train_data = pd.concat([fraud_train, legit_train])\n",
        "train_data = train_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "df = train_data\n",
        "\n",
        "# Generate synthetic fraud data\n",
        "num_synthetic_samples = len(df[df['Class'] == 0]) - len(df[df['Class'] == 1])  # Balance the dataset\n",
        "synthetic_data = []\n",
        "\n",
        "generator.eval()  # Set generator to evaluation mode\n",
        "\n",
        "# Generate the required number of synthetic samples\n",
        "while len(synthetic_data) < num_synthetic_samples:\n",
        "    z = torch.randn(batch_size, z_dim)\n",
        "    generated_data = generator(z).detach().numpy()\n",
        "    synthetic_data.extend(generated_data)\n",
        "\n",
        "# Trim to the exact number of samples needed\n",
        "synthetic_data = np.array(synthetic_data[:num_synthetic_samples])\n",
        "\n",
        "# Add 'Class' label to synthetic data\n",
        "synthetic_labels = np.ones((synthetic_data.shape[0], 1))  # Label as fraud (1)\n",
        "synthetic_data_with_labels = np.hstack((synthetic_data, synthetic_labels))\n",
        "\n",
        "# Combine synthetic and original data\n",
        "original_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/archive/creditcard.csv')\n",
        "synthetic_df = pd.DataFrame(synthetic_data_with_labels, columns=original_data.columns)\n",
        "balanced_data = pd.concat([original_data, synthetic_df], ignore_index=True)\n",
        "\n",
        "# Shuffle the dataset\n",
        "balanced_data = balanced_data.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Save the balanced dataset\n",
        "balanced_data.to_csv('/content/drive/MyDrive/Colab Notebooks/archive/balanced_creditcard.csv', index=False)\n",
        "\n",
        "print(f\"Synthetic fraud samples added: {len(synthetic_data)}\")\n",
        "print(f\"Balanced dataset saved to 'balanced_creditcard.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySyHie2cHudi",
        "outputId": "83565a7a-95fa-497a-9f67-b102a9577797"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic fraud samples added: 198676\n",
            "Balanced dataset saved to 'balanced_creditcard.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/archive/balanced_creditcard.csv')\n",
        "df = df.values\n",
        "x_train = df[:, 1:30]\n",
        "y_train = df[:, 30]"
      ],
      "metadata": {
        "id": "Vv-cugiqM7_d"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "def evaluate_model(model, x_train, y_train, x_legit_test, y_legit_test, x_fraud_test, y_fraud_test):\n",
        "    \"\"\"\n",
        "    Evaluates a given model on training and test data.\n",
        "\n",
        "    Args:\n",
        "        model: The machine learning model to evaluate.\n",
        "        x_train, y_train: Training data and labels.\n",
        "        x_legit_test, y_legit_test: Test data and labels for legitimate transactions.\n",
        "        x_fraud_test, y_fraud_test: Test data and labels for fraudulent transactions.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing:\n",
        "            - Legitimate accuracy\n",
        "            - Fraud accuracy\n",
        "    \"\"\"\n",
        "    # Train the model\n",
        "    model.fit(x_train, y_train)\n",
        "\n",
        "    # Evaluate accuracies\n",
        "    accuracy_legit = model.score(x_legit_test, y_legit_test)\n",
        "    accuracy_fraud = model.score(x_fraud_test, y_fraud_test)\n",
        "\n",
        "    return {\n",
        "        \"accuracy_legit\": accuracy_legit,\n",
        "        \"accuracy_fraud\": accuracy_fraud\n",
        "    }\n",
        "\n",
        "\n",
        "models = {\n",
        "    \"Decision Tree\": DecisionTreeClassifier(max_depth=4, random_state=42),\n",
        "    \"SVM\": SVC(kernel='rbf', random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "    \"AdaBoost\": AdaBoostClassifier(n_estimators=50, random_state=42),\n",
        "    \"GaussianNB\": GaussianNB(),\n",
        "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "}"
      ],
      "metadata": {
        "id": "XgEpEUojM4gX"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_fraud_test = fraud_test[:, 1:30]\n",
        "y_fraud_test = fraud_test[:, 30]\n",
        "\n",
        "x_legit_test = legit_test[:, 1:30]\n",
        "y_legit_test = legit_test[:, 30]\n",
        "\n",
        "print('X_train Shape:', x_train.shape)\n",
        "print('Y_train Shape:', y_train.shape)\n",
        "print('X_fraud_test Shape:', x_fraud_test.shape)\n",
        "print('Y_fraud_test Shape:', y_fraud_test.shape)\n",
        "print('X_legit_test Shape:', x_legit_test.shape)\n",
        "print('Y_legit_test Shape:', y_legit_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMtD18_VNwGs",
        "outputId": "2decfa17-9444-4de3-ab59-555ee62069f5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train Shape: (483483, 29)\n",
            "Y_train Shape: (483483,)\n",
            "X_fraud_test Shape: (148, 29)\n",
            "Y_fraud_test Shape: (148,)\n",
            "X_legit_test Shape: (85295, 29)\n",
            "Y_legit_test Shape: (85295,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "for model_name, model in models.items():\n",
        "    print(f\"Evaluating {model_name}...\")\n",
        "    results[model_name] = evaluate_model(model, x_train, y_train, x_legit_test, y_legit_test, x_fraud_test, y_fraud_test)\n",
        "    print(f\"{model_name} Legit Accuracy: {results[model_name]['accuracy_legit']:.5f}\")\n",
        "    print(f\"{model_name} Fraud Accuracy: {results[model_name]['accuracy_fraud']:.5f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKy3erRYO7xm",
        "outputId": "6908a4b3-95c9-4176-fb16-00f2d8f65fa9"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Decision Tree...\n",
            "Decision Tree Legit Accuracy: 0.99972\n",
            "Decision Tree Fraud Accuracy: 0.75676\n",
            "Evaluating SVM...\n",
            "SVM Legit Accuracy: 0.99965\n",
            "SVM Fraud Accuracy: 0.01351\n",
            "Evaluating Random Forest...\n",
            "Random Forest Legit Accuracy: 1.00000\n",
            "Random Forest Fraud Accuracy: 1.00000\n",
            "Evaluating Logistic Regression...\n",
            "Logistic Regression Legit Accuracy: 0.99985\n",
            "Logistic Regression Fraud Accuracy: 0.62162\n",
            "Evaluating AdaBoost...\n",
            "AdaBoost Legit Accuracy: 0.99923\n",
            "AdaBoost Fraud Accuracy: 0.60811\n",
            "Evaluating GaussianNB...\n",
            "GaussianNB Legit Accuracy: 1.00000\n",
            "GaussianNB Fraud Accuracy: 0.00000\n",
            "Evaluating KNN...\n",
            "KNN Legit Accuracy: 0.99991\n",
            "KNN Fraud Accuracy: 0.71622\n",
            "Evaluating XGBoost...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [19:17:00] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Legit Accuracy: 1.00000\n",
            "XGBoost Fraud Accuracy: 1.00000\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}