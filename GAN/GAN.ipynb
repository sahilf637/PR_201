{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/saumyaryan/Documents/PR/PR_201/Files/creditcard.csv')\n",
    "\n",
    "# Select features (excluding label 'Fraud')\n",
    "df = df[df['Class'] == 1]\n",
    "features = df.drop(columns=['Class']).values\n",
    "labels = df['Class'].values  # Use labels for evaluation, not for GAN training\n",
    "\n",
    "# Normalize the data for better GAN performance\n",
    "scaler = MinMaxScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "real_data = torch.tensor(features_scaled, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator Model\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, output_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Discriminator Model\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = real_data.shape[1]  # Number of features in the dataset\n",
    "z_dim = 20  # Latent space size for generator\n",
    "\n",
    "generator = Generator(z_dim, input_dim)\n",
    "discriminator = Discriminator(input_dim)\n",
    "\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "lr = 0.0002\n",
    "\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0001)  # Slower learning for D\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10000, D Loss: 1.5405288934707642, G Loss: 0.6990412473678589\n",
      "Epoch 1000/10000, D Loss: 1.282390832901001, G Loss: 0.7915784120559692\n",
      "Epoch 2000/10000, D Loss: 1.3745840787887573, G Loss: 0.7155547142028809\n",
      "Epoch 3000/10000, D Loss: 1.3551385402679443, G Loss: 0.7446081638336182\n",
      "Epoch 4000/10000, D Loss: 1.3326581716537476, G Loss: 0.7493083477020264\n",
      "Epoch 5000/10000, D Loss: 1.3552424907684326, G Loss: 0.781499445438385\n",
      "Epoch 6000/10000, D Loss: 1.3720362186431885, G Loss: 0.6782967448234558\n",
      "Epoch 7000/10000, D Loss: 1.4089906215667725, G Loss: 0.7071007490158081\n",
      "Epoch 8000/10000, D Loss: 1.4820038080215454, G Loss: 0.6851615309715271\n",
      "Epoch 9000/10000, D Loss: 1.3936870098114014, G Loss: 0.7175788879394531\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 10000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Select a random batch from real data\n",
    "    idx = torch.randint(0, real_data.size(0), (batch_size,))\n",
    "    real_batch = real_data[idx]\n",
    "\n",
    "    noise = torch.randn_like(real_batch) * 0.05\n",
    "    real_batch_noisy = real_batch + noise\n",
    "\n",
    "\n",
    "    # Generate fake data\n",
    "    z = torch.randn(batch_size, z_dim)\n",
    "    fake_data = generator(z)\n",
    "\n",
    "    # Labels for real (1) and fake (0)\n",
    "    real_labels = torch.full((batch_size, 1), 0.9)  # Instead of 1\n",
    "    fake_labels = torch.full((batch_size, 1), 0.1)  # Instead of 0\n",
    "\n",
    "\n",
    "    # Train Discriminator\n",
    "    real_loss = criterion(discriminator(real_batch_noisy), real_labels)\n",
    "    fake_loss = criterion(discriminator(fake_data.detach()), fake_labels)\n",
    "    d_loss = real_loss + fake_loss\n",
    "\n",
    "    optimizer_D.zero_grad()\n",
    "    d_loss.backward()\n",
    "    optimizer_D.step()\n",
    "\n",
    "    # Train Generator\n",
    "    g_loss = criterion(discriminator(fake_data), real_labels)\n",
    "\n",
    "    optimizer_G.zero_grad()\n",
    "    g_loss.backward()\n",
    "    optimizer_G.step()\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Epoch {epoch}/{num_epochs}, D Loss: {d_loss.item()}, G Loss: {g_loss.item()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
